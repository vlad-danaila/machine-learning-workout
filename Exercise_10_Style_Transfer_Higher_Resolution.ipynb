{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 10 Style Transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlad-danaila/machine-learning-workout/blob/master/Exercise_10_Style_Transfer_Higher_Resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBX2k6evXED3",
        "colab_type": "text"
      },
      "source": [
        "**Style Transfer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Uyjl_SWSqU",
        "colab_type": "code",
        "outputId": "2506c3ee-7731-4c9b-dcc1-244d79088825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6idO5mZWGp0",
        "colab_type": "code",
        "outputId": "87dc3b96-73b8-4c5e-88a5-34cfd80061a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.0+cu100)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.1+cu100)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rrP63MsXLPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch as t\n",
        "import torchvision as tv\n",
        "import PIL as pil\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBHmIHXLeqK_",
        "colab_type": "text"
      },
      "source": [
        "**Img Loading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBpUnea4WMgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalization = .5, .5, .5\n",
        "\n",
        "def load_image(path, size):\n",
        "\n",
        "  transforms = tv.transforms.Compose([\n",
        "    tv.transforms.Resize(size),\n",
        "    tv.transforms.ToTensor(),\n",
        "    tv.transforms.Lambda(lambda img: img.cuda()),\n",
        "    tv.transforms.Normalize(normalization, normalization) \n",
        "  ])\n",
        "  return transforms(pil.Image.open(path).convert('RGB'))\n",
        "\n",
        "def load_images(size, path_content, path_style):\n",
        "  content = load_image(path_content, size)\n",
        "  style = load_image(path_style, size)\n",
        "  result = content.clone().requires_grad_(True)\n",
        "  return content, style, result\n",
        "\n",
        "def to_numpy(x):\n",
        "  return x.cpu().detach().numpy()\n",
        "\n",
        "def img_to_numpy(img):\n",
        "  img = np.transpose(to_numpy(img), (1, 2, 0))\n",
        "  return img * normalization + normalization\n",
        "  \n",
        "def plot_img(img):\n",
        "  plt.imshow(img_to_numpy(img))\n",
        "  plt.show()\n",
        "  \n",
        "def save_img(img, path):\n",
        "  plt.imsave(path, img_to_numpy(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jQG-FX_etIy",
        "colab_type": "text"
      },
      "source": [
        "**Define Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qWHoLtrbvCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tv.models.vgg19(pretrained = True).cuda()\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tznAxplDf_xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_layers = {0, 5, 10, 19, 28}\n",
        "content_layers = {21}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT607xbTtxuW",
        "colab_type": "text"
      },
      "source": [
        "**Load Features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIGEPVHKXYjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feats(img):\n",
        "  img = img.unsqueeze(0)\n",
        "  feats_style, feats_content = {}, {}\n",
        "  for i in range(0, max(style_layers) + 1):\n",
        "    img = model.features[i](img)\n",
        "    if i in style_layers:\n",
        "      feats_style[i] = img.squeeze(0)\n",
        "    elif i in content_layers:\n",
        "      feats_content[i] = img.squeeze(0)\n",
        "  return feats_content, feats_style\n",
        "\n",
        "def load_feats_content_and_style(content, style):\n",
        "    feats_content = get_feats(content)[0]\n",
        "    feats_style = get_feats(style)[1]\n",
        "    return feats_content, feats_style\n",
        "\n",
        "def gram(x):\n",
        "  x = x.view(x.shape[0], -1)\n",
        "  return t.matmul(x, x.t())\n",
        "\n",
        "def gram_style(style_feats):\n",
        "  return { k: gram(style_feats[k]) for k in style_feats }\n",
        "\n",
        "def get_content_and_gram_style(content, style):\n",
        "  feats_content, feats_style = load_feats_content_and_style(content, style)\n",
        "  style_grams = gram_style(feats_style)\n",
        "  return feats_content, style_grams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4uhKyLquVWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_content = '/content/drive/My Drive/city.jpg'\n",
        "path_style = '/content/drive/My Drive/starry_night.jpg'\n",
        "out_img_path = 'City starry night.png'\n",
        "steps = 101\n",
        "size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfUvQ9558cQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def style_transfer(path_content, path_style, out_img_path, size, steps):\n",
        "  content, style, result = load_images(size, path_content, path_style)  \n",
        "  feats_content, style_grams = get_content_and_gram_style(content, style)\n",
        "  optimizer = t.optim.Adam([result], 1e-3)\n",
        "  loss_fn = t.nn.MSELoss()\n",
        "\n",
        "  for i in range(steps):\n",
        "    feats_result_content, feats_result_style = get_feats(result)\n",
        "    result_gram_style = gram_style(feats_result_style)\n",
        "    loss = t.tensor(0.).cuda().requires_grad_(True)\n",
        "    for layer in result_gram_style:\n",
        "      loss = loss + loss_fn(result_gram_style[layer], style_grams[layer])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    if i % 100 == 0:\n",
        "      print('Step', i + 1)\n",
        "      plot_img(result)\n",
        "  print(out_img_path)\n",
        "  save_img(result, out_img_path)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0isPBo0b2Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2MG8n3T8uhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "style_transfer(path_content, path_style, out_img_path, size, 3000)\n",
        "\n",
        "style_transfer(out_img_path, path_style, out_img_path, size * 2, 1000)\n",
        "\n",
        "style_transfer(out_img_path, path_style, out_img_path, size * 4, 1000)\n",
        "\n",
        "style_transfer(out_img_path, path_style, out_img_path, size * 8, 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}